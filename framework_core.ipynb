{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CyberBrain: Cybersecurity in BCI for Advanced Driver Assistance\n",
    "## Milestone MS3: Framework to detect and measure the cyberattacks impact.\n",
    "#### University of Murcia, Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset=\"dataset/p300-umu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(dataset, 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Acquiring signals...\n"
     ]
    }
   ],
   "source": [
    "from framework_acquisition import *\n",
    "\n",
    "def framework_acquisition():\n",
    "\n",
    "    time.sleep(2)\n",
    "    print(\"[+] Acquiring signals...\")\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind((HOST, PORT))\n",
    "        s.listen()\n",
    "        conn, addr = s.accept()\n",
    "        with open(\"rawdata.csv\", \"wb\") as f:\n",
    "            print(f\"Connected by {addr}\")\n",
    "            while True:\n",
    "                bytes_read = conn.recv(BUFFER_SIZE)\n",
    "                if not bytes_read:\n",
    "                    print(\"Finished file transfer\")\n",
    "                    break\n",
    "                f.write(bytes_read)\n",
    "        f.close()\n",
    "        conn.close()\n",
    "        print(\"File transfer complete\")\n",
    "\n",
    "t = threading.Thread(name='framework_acquisition', target=framework_acquisition)\n",
    "t.start()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subjects = {}\n",
    "for i, d in enumerate(data):\n",
    "    subjects[f'Subject {i}'] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Subject 0': <EpochsArray |  3982 events (all good), 0 - 0.585938 sec, baseline off, ~37.0 MB, data loaded,\n",
       "  'neg': 3413\n",
       "  'pos': 569>,\n",
       " 'Subject 1': <EpochsArray |  3916 events (all good), 0 - 0.585938 sec, baseline off, ~36.4 MB, data loaded,\n",
       "  'neg': 3362\n",
       "  'pos': 554>,\n",
       " 'Subject 2': <EpochsArray |  2053 events (all good), 0 - 0.585938 sec, baseline off, ~19.1 MB, data loaded,\n",
       "  'neg': 1760\n",
       "  'pos': 293>,\n",
       " 'Subject 3': <EpochsArray |  6516 events (all good), 0 - 0.585938 sec, baseline off, ~60.5 MB, data loaded,\n",
       "  'neg': 5589\n",
       "  'pos': 927>,\n",
       " 'Subject 4': <EpochsArray |  3396 events (all good), 0 - 0.585938 sec, baseline off, ~31.5 MB, data loaded,\n",
       "  'neg': 2912\n",
       "  'pos': 484>,\n",
       " 'Subject 5': <EpochsArray |  3975 events (all good), 0 - 0.585938 sec, baseline off, ~36.9 MB, data loaded,\n",
       "  'neg': 3404\n",
       "  'pos': 571>,\n",
       " 'Subject 6': <EpochsArray |  1163 events (all good), 0 - 0.585938 sec, baseline off, ~10.8 MB, data loaded,\n",
       "  'neg': 871\n",
       "  'pos': 292>,\n",
       " 'Subject 7': <EpochsArray |  1174 events (all good), 0 - 0.585938 sec, baseline off, ~10.9 MB, data loaded,\n",
       "  'neg': 1006\n",
       "  'pos': 168>,\n",
       " 'Subject 8': <EpochsArray |  4139 events (all good), 0 - 0.585938 sec, baseline off, ~38.4 MB, data loaded,\n",
       "  'neg': 3549\n",
       "  'pos': 590>,\n",
       " 'Subject 9': <EpochsArray |  4047 events (all good), 0 - 0.585938 sec, baseline off, ~37.6 MB, data loaded,\n",
       "  'neg': 3466\n",
       "  'pos': 581>,\n",
       " 'Subject 10': <EpochsArray |  4060 events (all good), 0 - 0.585938 sec, baseline off, ~37.7 MB, data loaded,\n",
       "  'neg': 3479\n",
       "  'pos': 581>,\n",
       " 'Subject 11': <EpochsArray |  4067 events (all good), 0 - 0.585938 sec, baseline off, ~37.8 MB, data loaded,\n",
       "  'neg': 3487\n",
       "  'pos': 580>,\n",
       " 'Subject 12': <EpochsArray |  4083 events (all good), 0 - 0.585938 sec, baseline off, ~37.9 MB, data loaded,\n",
       "  'neg': 3503\n",
       "  'pos': 580>,\n",
       " 'Subject 13': <EpochsArray |  4024 events (all good), 0 - 0.585938 sec, baseline off, ~37.4 MB, data loaded,\n",
       "  'neg': 3449\n",
       "  'pos': 575>,\n",
       " 'Subject 14': <EpochsArray |  2263 events (all good), 0 - 0.585938 sec, baseline off, ~21.0 MB, data loaded,\n",
       "  'neg': 1953\n",
       "  'pos': 310>,\n",
       " 'Subject 15': <EpochsArray |  3809 events (all good), 0 - 0.585938 sec, baseline off, ~35.4 MB, data loaded,\n",
       "  'neg': 3259\n",
       "  'pos': 550>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = subjects['Subject 1']['pos']\n",
    "nonTarget = subjects['Subject 1']['neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_data = subjects['Subject 1']['pos'].get_data()\n",
    "nontarget_data = subjects['Subject 1']['neg'].get_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target and non-target labels are balanced for correct classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554, 16, 76)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3362, 16, 76)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nontarget_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alldata = X = np.concatenate([target_data, nontarget_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3916, 16, 76)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nontarget_data = nontarget_data[:593][:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "X = np.concatenate([target_data, nontarget_data])\n",
    "Y = np.concatenate([np.ones(target_data.shape[0]), np.zeros(nontarget_data.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147, 16, 76)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data storage layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nsamples, nx, ny = X.shape\n",
    "X_csv = X.reshape((nsamples,nx*ny))\n",
    "pd.DataFrame(X_csv, Y).to_csv(\"data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from cryptography.fernet import Fernet\n",
    "\n",
    "# key generation\n",
    "key = Fernet.generate_key()\n",
    "\n",
    "# string the key in a file\n",
    "with open('password.key', 'wb') as passwordfile:\n",
    "    passwordfile.write(key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encrypt the file using the key generated\n",
    "\n",
    "Now we have an encrypted key and file to be encrypted. Now write code to encrypt this file:\n",
    "- Open the file that contains the key.\n",
    "- Initialize the Fernet object.\n",
    "- Read the original file.\n",
    "- Encrypt the file and store it.\n",
    "- Then write the encrypted data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "with open('password.key', 'rb') as passwordfile:\n",
    "    key = passwordfile.read()\n",
    "\n",
    "fernet = Fernet(key)\n",
    "\n",
    "with open('data.csv', 'rb') as file:\n",
    "    original = file.read()\n",
    "\n",
    "encrypted = fernet.encrypt(original)\n",
    "\n",
    "with open('data.csv.enc', 'wb') as encrypted_file:\n",
    "    encrypted_file.write(encrypted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data classification use case 1: P300 detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to perform a test of how use case 1 should work for P300 detection. For this, we have created a simple binary classifier that allows the detection of P300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with Logistic regression algorithm and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNoise(shape, maxNoise):\n",
    "    return np.random.normal(0.0, maxNoise, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results without noise\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NoTarget       0.78      0.77      0.78       593\n",
      "      Target       0.76      0.76      0.76       554\n",
      "\n",
      "    accuracy                           0.77      1147\n",
      "   macro avg       0.77      0.77      0.77      1147\n",
      "weighted avg       0.77      0.77      0.77      1147\n",
      "\n",
      "Classification results with low noise\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NoTarget       0.78      0.78      0.78       593\n",
      "      Target       0.76      0.76      0.76       554\n",
      "\n",
      "    accuracy                           0.77      1147\n",
      "   macro avg       0.77      0.77      0.77      1147\n",
      "weighted avg       0.77      0.77      0.77      1147\n",
      "\n",
      "Classification results with mid noise\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NoTarget       0.66      0.65      0.66       593\n",
      "      Target       0.63      0.65      0.64       554\n",
      "\n",
      "    accuracy                           0.65      1147\n",
      "   macro avg       0.65      0.65      0.65      1147\n",
      "weighted avg       0.65      0.65      0.65      1147\n",
      "\n",
      "Classification results with high noise\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NoTarget       0.60      0.56      0.58       593\n",
      "      Target       0.56      0.60      0.58       554\n",
      "\n",
      "    accuracy                           0.58      1147\n",
      "   macro avg       0.58      0.58      0.58      1147\n",
      "weighted avg       0.58      0.58      0.58      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross-validator instance\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Classifier instance\n",
    "clf = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression(solver='liblinear', C=1, class_weight=\"balanced\"))\n",
    "\n",
    "# Cross-validation process\n",
    "preds = np.empty(len(Y))\n",
    "predsNoiseLow = np.empty(len(Y))\n",
    "predsNoiseMid = np.empty(len(Y))\n",
    "predsNoiseHigh = np.empty(len(Y))\n",
    "\n",
    "for train, test in cv.split(X, Y):\n",
    "    clf.fit(X[train], Y[train]) # ajustar\n",
    "    preds[test] = clf.predict(X[test])\n",
    "    predsNoiseLow[test] = clf.predict(X[test]+generateNoise(X[test].shape, 0.001)) #\n",
    "    predsNoiseMid[test] = clf.predict(X[test]+generateNoise(X[test].shape, 0.4)) #\n",
    "    predsNoiseHigh[test] = clf.predict(X[test]+generateNoise(X[test].shape, 0.8)) #\n",
    "\n",
    "\n",
    "# Process information\n",
    "target_names = ['NoTarget', 'Target']\n",
    "report = classification_report(Y, preds, target_names=target_names)\n",
    "reportNoiseLow = classification_report(Y, predsNoiseLow, target_names=target_names)\n",
    "reportNoiseMid = classification_report(Y, predsNoiseMid, target_names=target_names)\n",
    "reportNoiseHigh = classification_report(Y, predsNoiseHigh, target_names=target_names)\n",
    "\n",
    "print(\"Classification results without noise\")\n",
    "print(report)\n",
    "print(\"Classification results with low noise\")\n",
    "print(reportNoiseLow)\n",
    "print(\"Classification results with mid noise\")\n",
    "print(reportNoiseMid)\n",
    "print(\"Classification results with high noise\")\n",
    "print(reportNoiseHigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with Random Forest algorithm and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results without noise\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NoTarget       0.69      0.81      0.74       593\n",
      "      Target       0.75      0.60      0.67       554\n",
      "\n",
      "    accuracy                           0.71      1147\n",
      "   macro avg       0.72      0.71      0.71      1147\n",
      "weighted avg       0.72      0.71      0.71      1147\n",
      "\n",
      "Classification results with low noise\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NoTarget       0.69      0.82      0.75       593\n",
      "      Target       0.75      0.60      0.67       554\n",
      "\n",
      "    accuracy                           0.71      1147\n",
      "   macro avg       0.72      0.71      0.71      1147\n",
      "weighted avg       0.72      0.71      0.71      1147\n",
      "\n",
      "Classification results with mid noise\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NoTarget       0.69      0.80      0.74       593\n",
      "      Target       0.75      0.62      0.68       554\n",
      "\n",
      "    accuracy                           0.71      1147\n",
      "   macro avg       0.72      0.71      0.71      1147\n",
      "weighted avg       0.72      0.71      0.71      1147\n",
      "\n",
      "Classification results with high noise\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NoTarget       0.61      0.51      0.55       593\n",
      "      Target       0.55      0.66      0.60       554\n",
      "\n",
      "    accuracy                           0.58      1147\n",
      "   macro avg       0.58      0.58      0.58      1147\n",
      "weighted avg       0.58      0.58      0.58      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "nsamples, nx, ny = X.shape\n",
    "X_train_2d = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "# Cross-validation process\n",
    "preds = np.empty(len(Y))\n",
    "predsNoiseLow = np.empty(len(Y))\n",
    "predsNoiseMid = np.empty(len(Y))\n",
    "predsNoiseHigh = np.empty(len(Y))\n",
    "\n",
    "for train, test in cv.split(X, Y):\n",
    "    clf.fit(X_train_2d[train], Y[train]) # ajustar\n",
    "    preds[test] = clf.predict(X_train_2d[test])\n",
    "    predsNoiseLow[test] = clf.predict(X_train_2d[test]+generateNoise(X_train_2d[test].shape, 0.001)) #\n",
    "    predsNoiseMid[test] = clf.predict(X_train_2d[test]+generateNoise(X_train_2d[test].shape, 1)) #\n",
    "    predsNoiseHigh[test] = clf.predict(X_train_2d[test]+generateNoise(X_train_2d[test].shape, 3)) #\n",
    "\n",
    "# Process information\n",
    "target_names = ['NoTarget', 'Target']\n",
    "report = classification_report(Y, preds, target_names=target_names)\n",
    "reportNoiseLow = classification_report(Y, predsNoiseLow, target_names=target_names)\n",
    "reportNoiseMid = classification_report(Y, predsNoiseMid, target_names=target_names)\n",
    "reportNoiseHigh = classification_report(Y, predsNoiseHigh, target_names=target_names)\n",
    "\n",
    "print(\"Classification results without noise\")\n",
    "print(report)\n",
    "print(\"Classification results with low noise\")\n",
    "print(reportNoiseLow)\n",
    "print(\"Classification results with mid noise\")\n",
    "print(reportNoiseMid)\n",
    "print(\"Classification results with high noise\")\n",
    "print(reportNoiseHigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the algorithms yield about 75% accuracy in classifying the P300. This could be improved by adjusting their hyperparameters, although this is not the objective. Noise is then applied to the signal until the previously trained classifier is unable to recognize the different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset in 50% clean and 50% with noise\n",
    "X_clean, X_noise = train_test_split(X, test_size=0.50, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_clean.shape\n",
    "X_clean_2d = X_clean.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = X_noise.shape\n",
    "X_noise_2d = X_noise.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create an unsupervised classification model to detect this noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination_factor = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model based on the IForest algorithm is trained with noise-free data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IForest(behaviour='old', bootstrap=False, contamination=0.05,\n",
       "    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=1,\n",
       "    random_state=42, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "\n",
    "clf = IForest(random_state=42, contamination=contamination_factor)\n",
    "\n",
    "# Model training\n",
    "clf.fit(X_clean_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model based on the One-Class Support Vector Machine algorithm is trained with noise-free data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCSVM(cache_size=200, coef0=0.0, contamination=0.05, degree=3, gamma=1e-05,\n",
       "   kernel='rbf', max_iter=-1, nu=0.5, shrinking=True, tol=0.001,\n",
       "   verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.ocsvm import OCSVM\n",
    "\n",
    "clfOCSV = OCSVM(kernel='rbf',gamma=0.00001, contamination=contamination_factor)\n",
    "\n",
    "# Model training\n",
    "clfOCSV.fit(X_clean_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier results are obtained with noise-free data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowNoise = generateNoise(X_noise_2d.shape, 0.001)\n",
    "midNoise = generateNoise(X_noise_2d.shape, 0.4)\n",
    "highNoise = generateNoise(X_noise_2d.shape, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [0 1]      [540  34]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_noise_2d)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [0 1]      [548  26]\n"
     ]
    }
   ],
   "source": [
    "pred = clfOCSV.predict(X_noise_2d)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen how it identifies two different classes, this may be due to the differences in a signal in the p300 and non p300 stages. Next, we will add noise to the signal to see how the classifier behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with low noise\n",
      "\t [0 1]      [540  34]\n",
      "Predictions with mid noise\n",
      "\t [0 1]      [143 431]\n",
      "Predictions with high noise\n",
      "\t [1]      [574]\n"
     ]
    }
   ],
   "source": [
    "predLow = clf.predict(X_noise_2d + lowNoise)\n",
    "predMid = clf.predict(X_noise_2d + midNoise)\n",
    "predHigh = clf.predict(X_noise_2d + highNoise)\n",
    "\n",
    "print(\"Predictions with low noise\")\n",
    "unique_elements, counts_elements = np.unique(predLow, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)\n",
    "print(\"Predictions with mid noise\")\n",
    "unique_elements, counts_elements = np.unique(predMid, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)\n",
    "print(\"Predictions with high noise\")\n",
    "unique_elements, counts_elements = np.unique(predHigh, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with low noise\n",
      "\t [0 1]      [548  26]\n",
      "Predictions with mid noise\n",
      "\t [0 1]      [122 452]\n",
      "Predictions with high noise\n",
      "\t [1]      [574]\n"
     ]
    }
   ],
   "source": [
    "predLow = clfOCSV.predict(X_noise_2d + lowNoise)\n",
    "predMid = clfOCSV.predict(X_noise_2d + midNoise)\n",
    "predHigh = clfOCSV.predict(X_noise_2d + highNoise)\n",
    "\n",
    "print(\"Predictions with low noise\")\n",
    "unique_elements, counts_elements = np.unique(predLow, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)\n",
    "print(\"Predictions with mid noise\")\n",
    "unique_elements, counts_elements = np.unique(predMid, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)\n",
    "print(\"Predictions with high noise\")\n",
    "unique_elements, counts_elements = np.unique(predHigh, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador binario para ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.20, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "X_mix = []\n",
    "Y_mix =[]\n",
    "for i in X_train:\n",
    "    if(cont%2 == 0):\n",
    "        noise = generateNoise(i.shape, 0.1)\n",
    "        X_mix.append(i+noise)\n",
    "        Y_mix.append(1)\n",
    "    else:\n",
    "        X_mix.append(i)\n",
    "        Y_mix.append(0)\n",
    "    cont+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "X_mix_train = np.array(X_mix)\n",
    "Y_mix_train = np.array(Y_mix)\n",
    "\n",
    "nsamples, nx, ny = X_mix_train.shape\n",
    "X_mix_train_2d = X_mix_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "clf.fit(X_mix_train_2d, Y_mix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "X_mix_test = []\n",
    "Y_mix_test =[]\n",
    "for i in X_test:\n",
    "    if(cont%2 == 0):\n",
    "        noise = generateNoise(i.shape, 0.8)\n",
    "        X_mix_test.append(i+noise)\n",
    "        Y_mix_test.append(1)\n",
    "    else:\n",
    "        X_mix_test.append(i)\n",
    "        Y_mix_test.append(0)\n",
    "    cont+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     NoNoise       0.71      0.50      0.59       115\n",
      "       Noise       0.61      0.79      0.69       115\n",
      "\n",
      "    accuracy                           0.65       230\n",
      "   macro avg       0.66      0.65      0.64       230\n",
      "weighted avg       0.66      0.65      0.64       230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_mix_test = np.array(X_mix_test)\n",
    "Y_mix_test = np.array(Y_mix_test)\n",
    "\n",
    "nsamples, nx, ny = X_mix_test.shape\n",
    "X_mix_test_2d = X_mix_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "pred = clf.predict(X_mix_test_2d)\n",
    "target_names = ['NoNoise', 'Noise']\n",
    "report = classification_report(Y_mix_test, pred, target_names=target_names)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}