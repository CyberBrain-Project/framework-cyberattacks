{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CyberBrain: Cybersecurity in BCI for Advanced Driver Assistance\n",
    "## Milestone MS3: Framework to detect and measure the cyberattacks impact.\n",
    "#### University of Murcia, Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: https://univmurcia-my.sharepoint.com/:u:/g/personal/enriquetomas_um_es/EUqf9NlxBC9HudvMJ4FUvJMBcU4ngGDug5bobNka_p9FwQ?e=Rx1lc3\r\n"
     ]
    }
   ],
   "source": [
    "!wget -O dataset/p300-umu https://univmurcia-my.sharepoint.com/:u:/g/personal/enriquetomas_um_es/EUqf9NlxBC9HudvMJ4FUvJMBcU4ngGDug5bobNka_p9FwQ?e=Rx1lc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset=\"dataset/p300-umu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(dataset, 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from framework_acquisition import *\n",
    "t = threading.Thread(name='framework_acquisition', target=acquire_signals(), args=(data,))\n",
    "t.start()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subjects = {}\n",
    "for i, d in enumerate(data):\n",
    "    subjects[f'Subject {i}'] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'Subject 0': <EpochsArray |  3982 events (all good), 0 - 0.585938 sec, baseline off, ~37.0 MB, data loaded,\n  'neg': 3413\n  'pos': 569>,\n 'Subject 1': <EpochsArray |  3916 events (all good), 0 - 0.585938 sec, baseline off, ~36.4 MB, data loaded,\n  'neg': 3362\n  'pos': 554>,\n 'Subject 2': <EpochsArray |  2053 events (all good), 0 - 0.585938 sec, baseline off, ~19.1 MB, data loaded,\n  'neg': 1760\n  'pos': 293>,\n 'Subject 3': <EpochsArray |  6516 events (all good), 0 - 0.585938 sec, baseline off, ~60.5 MB, data loaded,\n  'neg': 5589\n  'pos': 927>,\n 'Subject 4': <EpochsArray |  3396 events (all good), 0 - 0.585938 sec, baseline off, ~31.5 MB, data loaded,\n  'neg': 2912\n  'pos': 484>,\n 'Subject 5': <EpochsArray |  3975 events (all good), 0 - 0.585938 sec, baseline off, ~36.9 MB, data loaded,\n  'neg': 3404\n  'pos': 571>,\n 'Subject 6': <EpochsArray |  1163 events (all good), 0 - 0.585938 sec, baseline off, ~10.8 MB, data loaded,\n  'neg': 871\n  'pos': 292>,\n 'Subject 7': <EpochsArray |  1174 events (all good), 0 - 0.585938 sec, baseline off, ~10.9 MB, data loaded,\n  'neg': 1006\n  'pos': 168>,\n 'Subject 8': <EpochsArray |  4139 events (all good), 0 - 0.585938 sec, baseline off, ~38.4 MB, data loaded,\n  'neg': 3549\n  'pos': 590>,\n 'Subject 9': <EpochsArray |  4047 events (all good), 0 - 0.585938 sec, baseline off, ~37.6 MB, data loaded,\n  'neg': 3466\n  'pos': 581>,\n 'Subject 10': <EpochsArray |  4060 events (all good), 0 - 0.585938 sec, baseline off, ~37.7 MB, data loaded,\n  'neg': 3479\n  'pos': 581>,\n 'Subject 11': <EpochsArray |  4067 events (all good), 0 - 0.585938 sec, baseline off, ~37.8 MB, data loaded,\n  'neg': 3487\n  'pos': 580>,\n 'Subject 12': <EpochsArray |  4083 events (all good), 0 - 0.585938 sec, baseline off, ~37.9 MB, data loaded,\n  'neg': 3503\n  'pos': 580>,\n 'Subject 13': <EpochsArray |  4024 events (all good), 0 - 0.585938 sec, baseline off, ~37.4 MB, data loaded,\n  'neg': 3449\n  'pos': 575>,\n 'Subject 14': <EpochsArray |  2263 events (all good), 0 - 0.585938 sec, baseline off, ~21.0 MB, data loaded,\n  'neg': 1953\n  'pos': 310>,\n 'Subject 15': <EpochsArray |  3809 events (all good), 0 - 0.585938 sec, baseline off, ~35.4 MB, data loaded,\n  'neg': 3259\n  'pos': 550>}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = subjects['Subject 1']['pos']\n",
    "nonTarget = subjects['Subject 1']['neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_data = subjects['Subject 1']['pos'].get_data()\n",
    "nontarget_data = subjects['Subject 1']['neg'].get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(554, 16, 76)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(3362, 16, 76)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nontarget_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "alldata = X = np.concatenate([target_data, nontarget_data])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(3916, 16, 76)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nontarget_data = nontarget_data[:593][:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "X = np.concatenate([target_data, nontarget_data])\n",
    "Y = np.concatenate([np.ones(target_data.shape[0]), np.zeros(nontarget_data.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1147,)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(1147, 16, 76)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset in training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.10, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1032, 16, 76), (115, 16, 76))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1032,), (115,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1147, 16, 76), (1147,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NoTarget       0.78      0.77      0.78       593\n",
      "      Target       0.76      0.76      0.76       554\n",
      "\n",
      "    accuracy                           0.77      1147\n",
      "   macro avg       0.77      0.77      0.77      1147\n",
      "weighted avg       0.77      0.77      0.77      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Instancia validador cruzado\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Instancia clasificador\n",
    "clf = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression(solver='liblinear', C=1, class_weight=\"balanced\"))\n",
    "\n",
    "# Proceso de validación cruzada\n",
    "preds = np.empty(len(Y))\n",
    "for train, test in cv.split(X, Y):\n",
    "    clf.fit(X[train], Y[train]) # ajustar\n",
    "    preds[test] = clf.predict(X[test]) #\n",
    "\n",
    "# Info del proceso\n",
    "target_names = ['NoTarget', 'Target']\n",
    "report = classification_report(Y, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid = {'C': [0.1,1,10], 'gamma': [0.1,0.01],'kernel': ['rbf', 'linear']}\n",
    "#clf = SVC(kernel='linear', C=1, class_weight = \"balanced\")\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, param_grid)\n",
    "\n",
    "nsamples, nx, ny = X.shape\n",
    "d2_train_dataset = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "# Proceso de validación cruzada\n",
    "preds = np.empty(len(Y))\n",
    "for train, test in cv.split(d2_train_dataset, Y):\n",
    "    clf.fit(d2_train_dataset[train], Y[train]) # ajustar\n",
    "    preds[test] = clf.predict(d2_train_dataset[test]) #\n",
    "\n",
    "# Info del proceso\n",
    "target_names = ['NoTarget', 'Target']\n",
    "report = classification_report(Y, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NoTarget       0.69      0.81      0.74       593\n",
      "      Target       0.75      0.60      0.67       554\n",
      "\n",
      "    accuracy                           0.71      1147\n",
      "   macro avg       0.72      0.71      0.71      1147\n",
      "weighted avg       0.72      0.71      0.71      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "nsamples, nx, ny = X.shape\n",
    "d2_train_dataset = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "# Proceso de validación cruzada\n",
    "preds = np.empty(len(Y))\n",
    "for train, test in cv.split(d2_train_dataset, Y):\n",
    "    clf.fit(d2_train_dataset[train], Y[train]) # ajustar\n",
    "    preds[test] = clf.predict(d2_train_dataset[test]) #\n",
    "\n",
    "# Info del proceso\n",
    "target_names = ['NoTarget', 'Target']\n",
    "report = classification_report(Y, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRUEBAS CON NO SUPERVISADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "contamination_factor=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset in training and testing\n",
    "X_clean, X_noise = train_test_split(X, test_size=0.50, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean_train, X_clean_test = train_test_split(X_clean, test_size=0.10, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IForest(behaviour='old', bootstrap=False, contamination=0.05,\n",
       "    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=1,\n",
       "    random_state=42, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "\n",
    "#clf = OCSVM(kernel='rbf',gamma=0.0001, nu=0.3, contamination=contamination_factor)\n",
    "clf = IForest(random_state=42, contamination=contamination_factor)\n",
    "\n",
    "nsamples, nx, ny = X_clean_train.shape\n",
    "d2_train_clean_dataset = X_clean_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = X_clean_test.shape\n",
    "d2_test_clean_dataset = X_clean_test.reshape((nsamples,nx*ny))\n",
    "# Model training\n",
    "clf.fit(d2_train_clean_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador entrenado sin ruido prediciendo datos sin ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [0 1]      [50  8]\n"
     ]
    }
   ],
   "source": [
    "pred=clf.predict(d2_test_clean_dataset)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  -6.53015869   92.0860832   -46.75859684 ...   18.94242017\n",
      "    -29.76866507  110.57891308]\n",
      "  [ -18.51835213   -1.1854269   -10.956164   ...  -23.14063196\n",
      "     23.56420454  -34.61911915]\n",
      "  [  77.03099044  -23.18887769  -22.27294066 ...   60.01265066\n",
      "     -0.63109637   -2.10043766]\n",
      "  ...\n",
      "  [ -19.48227968   63.5393721    39.51911301 ...   54.29562978\n",
      "   -112.75854704   34.91757016]\n",
      "  [ -89.01850594  126.14737807   88.88634331 ...  105.37971778\n",
      "     68.27720412  -34.48569179]\n",
      "  [  14.43809266  -37.70635697  -12.37470283 ...   -2.04012648\n",
      "     -8.33414971  -51.98083302]]\n",
      "\n",
      " [[ -26.38269244  -17.61638872   34.72787825 ...  -36.93124892\n",
      "    152.78673524   51.21041514]\n",
      "  [ -42.98287436  -87.0475182   -40.19286665 ...   18.10124207\n",
      "    -42.48757432   91.01048778]\n",
      "  [ -30.29669154  -20.74235882  -46.10832565 ...   14.20207116\n",
      "    -61.08407644   48.91134349]\n",
      "  ...\n",
      "  [  -3.55697494  -99.89629985   -8.63897478 ...  -21.87627399\n",
      "    -27.13066509  -79.56213866]\n",
      "  [  27.71137859  -10.83226059  -66.96343771 ...   11.42782936\n",
      "     38.41088631  -37.42801401]\n",
      "  [ -21.79599585   11.19449613  -14.24339756 ...   35.47517246\n",
      "    -32.45775027  -58.49254242]]\n",
      "\n",
      " [[ -63.59408113    3.19122875  -49.45140664 ...   61.21807104\n",
      "     14.74891135   30.00429   ]\n",
      "  [ -25.7106833    43.28491544  -31.44602602 ...  -47.29195035\n",
      "    -34.09959411   71.75472575]\n",
      "  [  28.83603903  -26.27866177  -34.89015263 ...   58.03655269\n",
      "    -10.44949127   13.81584312]\n",
      "  ...\n",
      "  [   2.53713344 -103.7869868    24.07312545 ...   46.55367467\n",
      "   -113.95753834   20.22593192]\n",
      "  [ -25.97247201  118.38358852    4.45671912 ...   -8.5358954\n",
      "     31.01203813   -8.26018133]\n",
      "  [ 142.76833181  -69.09034573   -9.55506916 ...  170.56752194\n",
      "    -14.80371029   55.33966834]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  97.37492272  -70.11878781   -0.2189191  ...  -51.01573705\n",
      "     23.00205502  -26.40221135]\n",
      "  [ -76.07336674   89.57209424  -28.99612887 ...  -84.68371391\n",
      "    -67.83138413  -78.34877369]\n",
      "  [  -5.88393369   -4.49075121  -14.66299155 ...  -97.26015319\n",
      "    -24.87209603   -8.58507179]\n",
      "  ...\n",
      "  [ -46.72770646   50.61020697  -41.12897865 ...    0.28027566\n",
      "    -68.60540271   13.93078016]\n",
      "  [ -13.70162925   77.37395725  -81.67195477 ...   26.21386415\n",
      "     41.8183444    46.10894035]\n",
      "  [-139.59904536  -43.55935643   36.23908203 ...   50.93204464\n",
      "    -49.34032332   67.30273295]]\n",
      "\n",
      " [[  37.28380303  -79.13165012  -75.30186718 ...  -83.58228865\n",
      "     52.9659944   -31.68519253]\n",
      "  [ -37.99474244   46.08275797  107.41680353 ...    5.5499129\n",
      "    -52.76966726  126.72204946]\n",
      "  [  28.74585061  -35.83055102 -127.1836593  ... -134.36252171\n",
      "      7.87478595   25.49718706]\n",
      "  ...\n",
      "  [  16.03363206   51.08248284  -24.50875636 ...   53.51323882\n",
      "    -87.78088696   49.02719838]\n",
      "  [  68.11695956   52.98319362   48.00476149 ...   49.28691042\n",
      "     75.81041222   72.68700557]\n",
      "  [  -3.38059165   58.69882933   45.5513565  ...  -97.97302323\n",
      "    112.50611021  -92.95661745]]\n",
      "\n",
      " [[-116.81758621   17.72903337  -73.51221154 ...    0.43928053\n",
      "     -9.98237786  -32.06639929]\n",
      "  [  20.13357173  -47.26531833  -18.54325754 ...  -74.39650032\n",
      "     18.03489846  -59.0320245 ]\n",
      "  [ -42.15140495   -3.11570012  -63.12455794 ...  128.13099091\n",
      "     57.21831466   15.74459409]\n",
      "  ...\n",
      "  [ -47.56233525   67.67903413  147.80175236 ...   80.27135088\n",
      "    -40.82733363  -49.92664237]\n",
      "  [   0.34646801  -84.11083434  -54.31350371 ...    6.1889444\n",
      "     21.42855664    6.96593725]\n",
      "  [  -8.70726911  -80.22773412   83.82923946 ... -118.2258214\n",
      "    -36.45108142 -106.63324194]]]\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# max_noise = 0.000000001 # imperceptible a nivel de gráfica\n",
    "max_noise = 60 # perceptible a nivel de gráfica\n",
    "# Se crean muestras parametrizadas de una distribución normal (gaussiana) para generar ruido en la señal\n",
    "noise = np.random.normal(0.0, max_noise, X_noise.shape)\n",
    "\n",
    "print (noise[:50]) # muestra con los primeros 50 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noise = X_noise + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noise_train, X_noise_test = train_test_split(X_noise, test_size=0.10, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IForest(behaviour='old', bootstrap=False, contamination=0.05,\n",
       "    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=1,\n",
       "    random_state=42, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "\n",
    "#clf = OCSVM(kernel='rbf',gamma=0.0001, nu=0.3, contamination=contamination_factor)\n",
    "clfNoise = IForest(random_state=42, contamination=contamination_factor)\n",
    "\n",
    "\n",
    "nsamples, nx, ny = X_noise_train.shape\n",
    "d2_train_noise_dataset = X_noise_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = X_noise_test.shape\n",
    "d2_test_noise_dataset = X_noise_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "# Model training\n",
    "clfNoise.fit(d2_train_noise_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador entrenado con ruido prediciendo datos con ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [0 1]      [53  5]\n"
     ]
    }
   ],
   "source": [
    "pred=clfNoise.predict(d2_test_noise_dataset)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JUNTAMOS CLEAN + RUIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_concatenado = np.concatenate([X_clean_test, X_noise_test])\n",
    "\n",
    "nsamples, nx, ny = dataset_test_concatenado.shape\n",
    "dataset_test_concatenado = dataset_test_concatenado.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de clasificador entrenado sin ruido al predecir Clean+Ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [0 1]      [50 66]\n"
     ]
    }
   ],
   "source": [
    "pred=clf.predict(dataset_test_concatenado)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 16, 76)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_noise_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 16, 76)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de clasificador entrenado con ruido al predecir Clean+Ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [0 1]      [111   5]\n"
     ]
    }
   ],
   "source": [
    "pred=clfNoise.predict(dataset_test_concatenado)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento con datos combinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IForest(behaviour='old', bootstrap=False, contamination=0.05,\n",
       "    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=1,\n",
       "    random_state=42, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = OCSVM(kernel='rbf',gamma=0.0001, nu=0.3, contamination=contamination_factor)\n",
    "clfComb = IForest(random_state=42, contamination=contamination_factor)\n",
    "\n",
    "dataset_train_concatenado = np.concatenate([X_clean_train, X_noise_train])\n",
    "\n",
    "nsamples, nx, ny = dataset_train_concatenado.shape\n",
    "dataset_train_concatenado = dataset_train_concatenado.reshape((nsamples,nx*ny))\n",
    "\n",
    "# Model training\n",
    "clfComb.fit(dataset_train_concatenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [0 1]      [115   1]\n"
     ]
    }
   ],
   "source": [
    "pred=clfComb.predict(dataset_test_concatenado)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas con clasificador binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_noise = 0.000000001 # imperceptible a nivel de gráfica\n",
    "max_noise = 0.000000001 # perceptible a nivel de gráfica\n",
    "# Se crean muestras parametrizadas de una distribución normal (gaussiana) para generar ruido en la señal\n",
    "noise = np.random.normal(0.0, max_noise, target_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insertamos ruido solo a target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "X = np.concatenate([target_data+noise, nontarget_data])\n",
    "Y = np.concatenate([np.ones(target_data.shape[0]), np.zeros(nontarget_data.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     NoRuido       0.69      0.81      0.74       593\n",
      "       Ruido       0.75      0.60      0.67       554\n",
      "\n",
      "    accuracy                           0.71      1147\n",
      "   macro avg       0.72      0.71      0.71      1147\n",
      "weighted avg       0.72      0.71      0.71      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Instancia validador cruzado\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "nsamples, nx, ny = X.shape\n",
    "d2_train_dataset = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "# Instancia clasificador\n",
    "clf = make_pipeline(StandardScaler(),RandomForestClassifier(max_depth=2, random_state=0))\n",
    "\n",
    "# Proceso de validación cruzada\n",
    "preds = np.empty(len(Y))\n",
    "for train, test in cv.split(d2_train_dataset, Y):\n",
    "    clf.fit(d2_train_dataset[train], Y[train]) # ajustar\n",
    "    preds[test] = clf.predict(d2_train_dataset[test]) #\n",
    "\n",
    "# Info del proceso\n",
    "target_names = ['NoRuido', 'Ruido']\n",
    "report = classification_report(Y, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_noise = 0.000000001 # imperceptible a nivel de gráfica\n",
    "max_noise = 1 # perceptible a nivel de gráfica\n",
    "# Se crean muestras parametrizadas de una distribución normal (gaussiana) para generar ruido en la señal\n",
    "noise = np.random.normal(0.0, max_noise, nontarget_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probamos con non-target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "X = np.concatenate([target_data, nontarget_data+noise])\n",
    "Y = np.concatenate([np.ones(target_data.shape[0]), np.zeros(nontarget_data.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     NoRuido       0.99      0.99      0.99       593\n",
      "       Ruido       0.99      0.99      0.99       554\n",
      "\n",
      "    accuracy                           0.99      1147\n",
      "   macro avg       0.99      0.99      0.99      1147\n",
      "weighted avg       0.99      0.99      0.99      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instancia validador cruzado\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "nsamples, nx, ny = X.shape\n",
    "d2_train_dataset = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "# Instancia clasificador\n",
    "clf = make_pipeline(StandardScaler(),RandomForestClassifier(max_depth=2, random_state=0))\n",
    "\n",
    "# Proceso de validación cruzada\n",
    "preds = np.empty(len(Y))\n",
    "for train, test in cv.split(d2_train_dataset, Y):\n",
    "    clf.fit(d2_train_dataset[train], Y[train]) # ajustar\n",
    "    preds[test] = clf.predict(d2_train_dataset[test]) #\n",
    "\n",
    "# Info del proceso\n",
    "target_names = ['NoRuido', 'Ruido']\n",
    "report = classification_report(Y, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "X = np.concatenate([target_data, nontarget_data])\n",
    "Y = np.concatenate([np.zeros(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147, 16, 76)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generamos ruido de forma intermitente, pares=SI impares = N0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "max_noise = 0.001 # perceptible a nivel de gráfica\n",
    "X_mix = []\n",
    "Y_mix =[]\n",
    "for i in X:\n",
    "    if(cont%2 == 0):\n",
    "        noise = np.random.normal(0.0, max_noise, i.shape)\n",
    "        X_mix.append(i+noise)\n",
    "        Y_mix.append(1)\n",
    "    else:\n",
    "        X_mix.append(i)\n",
    "        Y_mix.append(0)\n",
    "    cont+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix = np.array(X_mix)\n",
    "Y_mix =np.array(Y_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     NoRuido       0.49      0.48      0.48       573\n",
      "       Ruido       0.49      0.50      0.50       574\n",
      "\n",
      "    accuracy                           0.49      1147\n",
      "   macro avg       0.49      0.49      0.49      1147\n",
      "weighted avg       0.49      0.49      0.49      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instancia validador cruzado\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "nsamples, nx, ny = X_mix.shape\n",
    "d2_train_dataset_mix = X_mix.reshape((nsamples,nx*ny))\n",
    "\n",
    "# Instancia clasificador\n",
    "clf = make_pipeline(StandardScaler(),RandomForestClassifier(max_depth=2, random_state=0))\n",
    "\n",
    "# Proceso de validación cruzada\n",
    "preds = np.empty(len(Y_mix))\n",
    "for train, test in cv.split(d2_train_dataset_mix, Y_mix):\n",
    "    clf.fit(d2_train_dataset_mix[train], Y_mix[train]) # ajustar\n",
    "    preds[test] = clf.predict(d2_train_dataset_mix[test]) #\n",
    "\n",
    "# Info del proceso\n",
    "target_names = ['NoRuido', 'Ruido']\n",
    "report = classification_report(Y_mix, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparamos con un no supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix_train, X_mix_test = train_test_split(X_mix, test_size=0.20, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IForest(behaviour='old', bootstrap=False, contamination=0.05,\n",
       "    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=1,\n",
       "    random_state=42, verbose=0)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#clf = OCSVM(kernel='rbf',gamma=0.0001, nu=0.3, contamination=contamination_factor)\n",
    "clfMix = IForest(random_state=42, contamination=contamination_factor)\n",
    "\n",
    "\n",
    "nsamples, nx, ny = X_mix_train.shape\n",
    "d2_train_mix_dataset = X_mix_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = X_mix_test.shape\n",
    "d2_test_mix_dataset = X_mix_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "# Model training\n",
    "clfMix.fit(d2_train_mix_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [0]      [230]\n"
     ]
    }
   ],
   "source": [
    "pred=clf.predict(d2_test_mix_dataset)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generamos ruido de forma aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "X_mix = []\n",
    "Y_mix =[]\n",
    "for i in X:\n",
    "    if(cont%2 == 0):\n",
    "        noise = np.random.normal(0.0, np.random.random_sample(), i.shape)\n",
    "        X_mix.append(i+noise)\n",
    "        Y_mix.append(1)\n",
    "    else:\n",
    "        X_mix.append(i)\n",
    "        Y_mix.append(0)\n",
    "    cont+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix_train, X_mix_test = train_test_split(X_mix, test_size=0.20, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix = np.array(X_mix)\n",
    "Y_mix =np.array(Y_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     NoRuido       0.72      0.94      0.82       573\n",
      "       Ruido       0.91      0.64      0.75       574\n",
      "\n",
      "    accuracy                           0.79      1147\n",
      "   macro avg       0.82      0.79      0.78      1147\n",
      "weighted avg       0.82      0.79      0.78      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instancia validador cruzado\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "nsamples, nx, ny = X_mix.shape\n",
    "d2_train_dataset_mix = X_mix.reshape((nsamples,nx*ny))\n",
    "\n",
    "# Instancia clasificador\n",
    "clf = make_pipeline(StandardScaler(),RandomForestClassifier(max_depth=2, random_state=0))\n",
    "\n",
    "# Proceso de validación cruzada\n",
    "preds = np.empty(len(Y_mix))\n",
    "for train, test in cv.split(d2_train_dataset_mix, Y_mix):\n",
    "    clf.fit(d2_train_dataset_mix[train], Y_mix[train]) # ajustar\n",
    "    preds[test] = clf.predict(d2_train_dataset_mix[test]) #\n",
    "\n",
    "# Info del proceso\n",
    "target_names = ['NoRuido', 'Ruido']\n",
    "report = classification_report(Y_mix, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix_train, X_mix_test = train_test_split(X_mix, test_size=0.20, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IForest(behaviour='old', bootstrap=False, contamination=0.05,\n",
       "    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=1,\n",
       "    random_state=42, verbose=0)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = OCSVM(kernel='rbf',gamma=0.0001, nu=0.3, contamination=contamination_factor)\n",
    "clfMix = IForest(random_state=42, contamination=contamination_factor)\n",
    "\n",
    "\n",
    "nsamples, nx, ny = X_mix_train.shape\n",
    "d2_train_mix_dataset = X_mix_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = X_mix_test.shape\n",
    "d2_test_mix_dataset = X_mix_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "# Model training\n",
    "clfMix.fit(d2_train_mix_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [0 1]      [153  77]\n"
     ]
    }
   ],
   "source": [
    "pred=clf.predict(d2_test_mix_dataset)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}