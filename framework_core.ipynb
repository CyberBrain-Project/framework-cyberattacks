{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CyberBrain: Cybersecurity in BCI for Advanced Driver Assistance\n",
    "## Milestone MS3: Framework to detect and measure the cyberattacks impact.\n",
    "#### University of Murcia, Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import threading\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Acquisition layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset=\"dataset/p300-umu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(dataset, 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from framework_acquisition import *\n",
    "t = threading.Thread(name='framework_acquisition', target=acquire_signals(), args=(data,))\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Processing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subjects = {}\n",
    "for i, d in enumerate(data):\n",
    "    subjects[f'Subject {i}'] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Subject 0': <EpochsArray |  3982 events (all good), 0 - 0.585938 sec, baseline off, ~37.0 MB, data loaded,\n",
       "  'neg': 3413\n",
       "  'pos': 569>,\n",
       " 'Subject 1': <EpochsArray |  3916 events (all good), 0 - 0.585938 sec, baseline off, ~36.4 MB, data loaded,\n",
       "  'neg': 3362\n",
       "  'pos': 554>,\n",
       " 'Subject 2': <EpochsArray |  2053 events (all good), 0 - 0.585938 sec, baseline off, ~19.1 MB, data loaded,\n",
       "  'neg': 1760\n",
       "  'pos': 293>,\n",
       " 'Subject 3': <EpochsArray |  6516 events (all good), 0 - 0.585938 sec, baseline off, ~60.5 MB, data loaded,\n",
       "  'neg': 5589\n",
       "  'pos': 927>,\n",
       " 'Subject 4': <EpochsArray |  3396 events (all good), 0 - 0.585938 sec, baseline off, ~31.5 MB, data loaded,\n",
       "  'neg': 2912\n",
       "  'pos': 484>,\n",
       " 'Subject 5': <EpochsArray |  3975 events (all good), 0 - 0.585938 sec, baseline off, ~36.9 MB, data loaded,\n",
       "  'neg': 3404\n",
       "  'pos': 571>,\n",
       " 'Subject 6': <EpochsArray |  1163 events (all good), 0 - 0.585938 sec, baseline off, ~10.8 MB, data loaded,\n",
       "  'neg': 871\n",
       "  'pos': 292>,\n",
       " 'Subject 7': <EpochsArray |  1174 events (all good), 0 - 0.585938 sec, baseline off, ~10.9 MB, data loaded,\n",
       "  'neg': 1006\n",
       "  'pos': 168>,\n",
       " 'Subject 8': <EpochsArray |  4139 events (all good), 0 - 0.585938 sec, baseline off, ~38.4 MB, data loaded,\n",
       "  'neg': 3549\n",
       "  'pos': 590>,\n",
       " 'Subject 9': <EpochsArray |  4047 events (all good), 0 - 0.585938 sec, baseline off, ~37.6 MB, data loaded,\n",
       "  'neg': 3466\n",
       "  'pos': 581>,\n",
       " 'Subject 10': <EpochsArray |  4060 events (all good), 0 - 0.585938 sec, baseline off, ~37.7 MB, data loaded,\n",
       "  'neg': 3479\n",
       "  'pos': 581>,\n",
       " 'Subject 11': <EpochsArray |  4067 events (all good), 0 - 0.585938 sec, baseline off, ~37.8 MB, data loaded,\n",
       "  'neg': 3487\n",
       "  'pos': 580>,\n",
       " 'Subject 12': <EpochsArray |  4083 events (all good), 0 - 0.585938 sec, baseline off, ~37.9 MB, data loaded,\n",
       "  'neg': 3503\n",
       "  'pos': 580>,\n",
       " 'Subject 13': <EpochsArray |  4024 events (all good), 0 - 0.585938 sec, baseline off, ~37.4 MB, data loaded,\n",
       "  'neg': 3449\n",
       "  'pos': 575>,\n",
       " 'Subject 14': <EpochsArray |  2263 events (all good), 0 - 0.585938 sec, baseline off, ~21.0 MB, data loaded,\n",
       "  'neg': 1953\n",
       "  'pos': 310>,\n",
       " 'Subject 15': <EpochsArray |  3809 events (all good), 0 - 0.585938 sec, baseline off, ~35.4 MB, data loaded,\n",
       "  'neg': 3259\n",
       "  'pos': 550>}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = subjects['Subject 1']['pos']\n",
    "nonTarget = subjects['Subject 1']['neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_data = subjects['Subject 1']['pos'].get_data()\n",
    "nontarget_data = subjects['Subject 1']['neg'].get_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554, 16, 76)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3362, 16, 76)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nontarget_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alldata = X = np.concatenate([target_data, nontarget_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3916, 16, 76)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nontarget_data = nontarget_data[:593][:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "X = np.concatenate([target_data, nontarget_data])\n",
    "Y = np.concatenate([np.ones(target_data.shape[0]), np.zeros(nontarget_data.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147, 16, 76)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data storage layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nsamples, nx, ny = X.shape\n",
    "X_csv = X.reshape((nsamples,nx*ny))\n",
    "pd.DataFrame(X_csv, Y).to_csv(\"data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from cryptography.fernet import Fernet\n",
    "\n",
    "# key generation\n",
    "key = Fernet.generate_key()\n",
    "\n",
    "# string the key in a file\n",
    "with open('password.key', 'wb') as passwordfile:\n",
    "    passwordfile.write(key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encrypt the file using the key generated\n",
    "\n",
    "Now we have an encrypted key and file to be encrypted. Now write code to encrypt this file:\n",
    "- Open the file that contains the key.\n",
    "- Initialize the Fernet object.\n",
    "- Read the original file.\n",
    "- Encrypt the file and store it.\n",
    "- Then write the encrypted data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "with open('password.key', 'rb') as passwordfile:\n",
    "    key = passwordfile.read()\n",
    "\n",
    "fernet = Fernet(key)\n",
    "\n",
    "with open('data.csv', 'rb') as file:\n",
    "    original = file.read()\n",
    "\n",
    "encrypted = fernet.encrypt(original)\n",
    "\n",
    "with open('data.csv.enc', 'wb') as encrypted_file:\n",
    "    encrypted_file.write(encrypted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data classification UC1: P300 detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to perform a test of how use case 1 should work for P300 detection. For this, we have created a simple binary classifier that allows the detection of P300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with Logistic regression algorithm and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonTarget       0.78      0.77      0.78       593\n",
      "      Target       0.76      0.76      0.76       554\n",
      "\n",
      "    accuracy                           0.77      1147\n",
      "   macro avg       0.77      0.77      0.77      1147\n",
      "weighted avg       0.77      0.77      0.77      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "clf = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression(solver='liblinear', C=1, class_weight=\"balanced\"))\n",
    "\n",
    "preds = np.empty(len(Y))\n",
    "for train, test in cv.split(X, Y):\n",
    "    clf.fit(X[train], Y[train])\n",
    "    preds[test] = clf.predict(X[test])\n",
    "\n",
    "target_names = ['NonTarget', 'Target']\n",
    "report = classification_report(Y, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with Support Vector Machine algorithm and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [37]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     12\u001B[0m preds \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty(\u001B[38;5;28mlen\u001B[39m(Y))\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m cv\u001B[38;5;241m.\u001B[39msplit(d2_train_dataset, Y):\n\u001B[0;32m---> 14\u001B[0m     \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43md2_train_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m     preds[test] \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mpredict(d2_train_dataset[test])\n\u001B[1;32m     17\u001B[0m target_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNonTarget\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTarget\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    885\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    886\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    887\u001B[0m     )\n\u001B[1;32m    889\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 891\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    894\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    895\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1392\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1390\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1391\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1392\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    831\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    832\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    833\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    834\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    835\u001B[0m         )\n\u001B[1;32m    836\u001B[0m     )\n\u001B[0;32m--> 838\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    840\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    841\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    842\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    843\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    844\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    857\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    858\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    859\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    860\u001B[0m     )\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/joblib/parallel.py:1046\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1043\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[1;32m   1044\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1046\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1047\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m   1049\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1050\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[1;32m   1051\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[1;32m   1052\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/joblib/parallel.py:861\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    860\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 861\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/joblib/parallel.py:779\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    778\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 779\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    780\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    781\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    783\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    784\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/joblib/parallel.py:262\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/joblib/parallel.py:262\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[0;32m--> 216\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:680\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    678\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    679\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 680\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    683\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[1;32m    684\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/sklearn/svm/_base.py:255\u001B[0m, in \u001B[0;36mBaseLibSVM.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    252\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LibSVM]\u001B[39m\u001B[38;5;124m\"\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    254\u001B[0m seed \u001B[38;5;241m=\u001B[39m rnd\u001B[38;5;241m.\u001B[39mrandint(np\u001B[38;5;241m.\u001B[39miinfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mi\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mmax)\n\u001B[0;32m--> 255\u001B[0m \u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msolver_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001B[39;00m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape_fit_ \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m (n_samples,)\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/sklearn/svm/_base.py:315\u001B[0m, in \u001B[0;36mBaseLibSVM._dense_fit\u001B[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001B[0m\n\u001B[1;32m    302\u001B[0m libsvm\u001B[38;5;241m.\u001B[39mset_verbosity_wrap(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[1;32m    304\u001B[0m \u001B[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001B[39;00m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# add other parameters to __init__\u001B[39;00m\n\u001B[1;32m    306\u001B[0m (\n\u001B[1;32m    307\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_,\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_vectors_,\n\u001B[1;32m    309\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_support,\n\u001B[1;32m    310\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdual_coef_,\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_,\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_probA,\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_probB,\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_status_,\n\u001B[0;32m--> 315\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[43mlibsvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[43msvm_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m    \u001B[49m\u001B[43mC\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnu\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprobability\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprobability\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdegree\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdegree\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshrinking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshrinking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    327\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    328\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcoef0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoef0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gamma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    331\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepsilon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    336\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_warn_from_fit_status()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid = {'C': [0.1,1,10], 'gamma': [0.1,0.01],'kernel': ['rbf', 'linear']}\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, param_grid)\n",
    "\n",
    "nsamples, nx, ny = X.shape\n",
    "d2_train_dataset = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "preds = np.empty(len(Y))\n",
    "for train, test in cv.split(d2_train_dataset, Y):\n",
    "    clf.fit(d2_train_dataset[train], Y[train])\n",
    "    preds[test] = clf.predict(d2_train_dataset[test])\n",
    "\n",
    "target_names = ['NonTarget', 'Target']\n",
    "report = classification_report(Y, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with Random Forest algorithm and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonTarget       0.69      0.81      0.74       593\n",
      "      Target       0.75      0.60      0.67       554\n",
      "\n",
      "    accuracy                           0.71      1147\n",
      "   macro avg       0.72      0.71      0.71      1147\n",
      "weighted avg       0.72      0.71      0.71      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "nsamples, nx, ny = X.shape\n",
    "d2_train_dataset = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "preds = np.empty(len(Y))\n",
    "for train, test in cv.split(d2_train_dataset, Y):\n",
    "    clf.fit(d2_train_dataset[train], Y[train])\n",
    "    preds[test] = clf.predict(d2_train_dataset[test])\n",
    "\n",
    "target_names = ['NonTarget', 'Target']\n",
    "report = classification_report(Y, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the algorithms yield about 75% accuracy in classifying the P300. This could be improved by adjusting their hyperparameters, although this is not the objective. Noise is then applied to the signal until the previously trained classifier is unable to recognize the different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [40]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m noise \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mnormal(\u001B[38;5;241m0.0\u001B[39m, max_noise, X[test]\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      6\u001B[0m X_test_noise \u001B[38;5;241m=\u001B[39m X[test] \u001B[38;5;241m+\u001B[39m noise\n\u001B[0;32m----> 8\u001B[0m preds \u001B[38;5;241m=\u001B[39m \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test_noise\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m     10\u001B[0m target_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNonTarget\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTarget\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     11\u001B[0m report \u001B[38;5;241m=\u001B[39m classification_report(Y[test], preds, target_names\u001B[38;5;241m=\u001B[39mtarget_names)\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:808\u001B[0m, in \u001B[0;36mForestClassifier.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    787\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    788\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    789\u001B[0m \u001B[38;5;124;03m    Predict class for X.\u001B[39;00m\n\u001B[1;32m    790\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    806\u001B[0m \u001B[38;5;124;03m        The predicted classes.\u001B[39;00m\n\u001B[1;32m    807\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 808\u001B[0m     proba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    810\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    811\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\u001B[38;5;241m.\u001B[39mtake(np\u001B[38;5;241m.\u001B[39margmax(proba, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:850\u001B[0m, in \u001B[0;36mForestClassifier.predict_proba\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    848\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    849\u001B[0m \u001B[38;5;66;03m# Check data\u001B[39;00m\n\u001B[0;32m--> 850\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_X_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;66;03m# Assign chunk of trees to jobs\u001B[39;00m\n\u001B[1;32m    853\u001B[0m n_jobs, _, _ \u001B[38;5;241m=\u001B[39m _partition_estimators(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_estimators, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:579\u001B[0m, in \u001B[0;36mBaseForest._validate_X_predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    576\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001B[39;00m\n\u001B[1;32m    578\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 579\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    580\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(X) \u001B[38;5;129;01mand\u001B[39;00m (X\u001B[38;5;241m.\u001B[39mindices\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc \u001B[38;5;129;01mor\u001B[39;00m X\u001B[38;5;241m.\u001B[39mindptr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc):\n\u001B[1;32m    581\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo support for np.int64 index based sparse matrices\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/sklearn/base.py:566\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    564\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    565\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[0;32m--> 566\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    567\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[0;32m~/miniforge3/envs/phd-workspace/lib/python3.9/site-packages/sklearn/utils/validation.py:794\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[1;32m    789\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    790\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to convert array of bytes/strings \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    791\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minto decimal numbers with dtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    792\u001B[0m         ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    793\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_nd \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[0;32m--> 794\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    795\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    796\u001B[0m         \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    797\u001B[0m     )\n\u001B[1;32m    799\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m    800\u001B[0m     _assert_all_finite(array, allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "# Maximum noise = 0.1\n",
    "max_noise = 0.1 # \n",
    "# Parameterized samples of a normal (Gaussian) distribution are created to generate noise in the signal.\n",
    "noise = np.random.normal(0.0, max_noise, X[test].shape)\n",
    "\n",
    "X_test_noise = X[test] + noise\n",
    "\n",
    "preds = clf.predict(X_test_noise) #\n",
    "\n",
    "target_names = ['NonTarget', 'Target']\n",
    "report = classification_report(Y[test], preds, target_names=target_names)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_noise = 0.8\n",
    "noise = np.random.normal(0.0, max_noise, X[test].shape)\n",
    "X_test_noise = X[test] + noise\n",
    "\n",
    "preds = clf.predict(X_test_noise) #\n",
    "\n",
    "target_names = ['NonTarget', 'Target']\n",
    "report = classification_report(Y[test], preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that with a maximum noise equal to 0.1, the classifier works correctly. However, when this noise is multiplied by 8, the classifier is unable to recognize the classes, therefore, this is our maximum noise allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create an unsupervised classification model to detect this noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset in 50% clean and 50% with noise\n",
    "X_clean, X_noise = train_test_split(X, test_size=0.50, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean_train, X_clean_test = train_test_split(X_clean, test_size=0.10, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination_factor = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model based on the IForest algorithm is trained with noise-free data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "IForest(behaviour='old', bootstrap=False, contamination=0.05,\n    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=1,\n    random_state=42, verbose=0)"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "\n",
    "clf = IForest(random_state=42, contamination=contamination_factor)\n",
    "\n",
    "nsamples, nx, ny = X_clean_train.shape\n",
    "d2_train_clean_dataset = X_clean_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = X_clean_test.shape\n",
    "d2_test_clean_dataset = X_clean_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "clf.fit(d2_train_clean_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model based on the One-Class Support Vector Machine algorithm is trained with noise-free data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "OCSVM(cache_size=200, coef0=0.0, contamination=0.05, degree=3, gamma=1e-05,\n   kernel='rbf', max_iter=-1, nu=0.5, shrinking=True, tol=0.001,\n   verbose=False)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.ocsvm import OCSVM\n",
    "\n",
    "clfOCSV = OCSVM(kernel='rbf',gamma=0.00001, contamination=contamination_factor)\n",
    "\n",
    "nsamples, nx, ny = X_clean_train.shape\n",
    "d2_train_clean_dataset = X_clean_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = X_clean_test.shape\n",
    "d2_test_clean_dataset = X_clean_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "clfOCSV.fit(d2_train_clean_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier results are obtained with noise-free data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [0 1]      [50  8]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(d2_test_clean_dataset)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [0 1]      [47 11]\n"
     ]
    }
   ],
   "source": [
    "pred = clfOCSV.predict(d2_test_clean_dataset)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen how it identifies two different classes, this may be due to the differences in a signal in the p300 and non p300 stages. Next, we will add noise to the signal to see how the classifier behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noise_train, X_noise_test = train_test_split(X_noise, test_size=0.10, random_state=42,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "X_noise_test_original = X_noise_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_noise = 0.8\n",
    "noise = np.random.normal(0.0, max_noise, X_noise_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noise_test = X_noise_test + noise\n",
    "\n",
    "nsamples, nx, ny = X_noise_test.shape\n",
    "X_noise_new = X_noise_test.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_noise_test_original.shape\n",
    "X_noise_test_original = X_noise_test_original.reshape((nsamples,nx*ny))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [1]      [58]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_noise_new)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wn = plt.scatter(X_noise_test_original[:,0], X_noise_test_original[:,1])\n",
    "yn = plt.scatter(X_noise_new[:,0], X_noise_new[:,1])\n",
    "\n",
    "plt.savefig('noise_added_scatter_08.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen how it identifies a single class related to the data with noise, which means that the classifier is working correctly. Next, we perform the last test in which data without noise and data with noise are combined in equal parts to test the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_concatenate = np.concatenate([X_clean_test, X_noise_test])\n",
    "\n",
    "nsamples, nx, ny = dataset_test_concatenate.shape\n",
    "X_test_comb = dataset_test_concatenate.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test_comb)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clfOCSV.predict(X_test_comb)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the results are very close to 50% identification for each class, so the results are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will perform a series of possible attacks for the case in which the attacker has more information about the use case and how the data is being treated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate noise with random value whose maximum is the previously defined threshold (0.8). It will be applied intermittently in order to affect stages with P300 and not P300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "X = np.concatenate([target_data, nontarget_data])\n",
    "Y = np.concatenate([np.zeros(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "X_mix = []\n",
    "Y_mix =[]\n",
    "for i in X:\n",
    "    if(cont%2 == 0):\n",
    "        noise = np.random.normal(0.0, np.random.uniform(0, 0.8), i.shape)\n",
    "        X_mix.append(i+noise)\n",
    "        Y_mix.append(1)\n",
    "    else:\n",
    "        X_mix.append(i)\n",
    "        Y_mix.append(0)\n",
    "    cont+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix_train, X_mix_test = train_test_split(X_mix, test_size=0.20, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix_test = np.array(X_mix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_mix_test.shape\n",
    "d2_test_mix_dataset = X_mix_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "pred=clf.predict(d2_test_mix_dataset)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clfOCSV.predict(d2_test_mix_dataset)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobación con poco ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "X = np.concatenate([target_data, nontarget_data])\n",
    "Y = np.concatenate([np.zeros(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "X_mix = []\n",
    "Y_mix =[]\n",
    "for i in X:\n",
    "    if(cont%2 == 0):\n",
    "        noise = np.random.normal(0.0, np.random.uniform(0, 0.1), i.shape)\n",
    "        X_mix.append(i+noise)\n",
    "        Y_mix.append(1)\n",
    "    else:\n",
    "        X_mix.append(i)\n",
    "        Y_mix.append(0)\n",
    "    cont+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix_train, X_mix_test = train_test_split(X_mix, test_size=0.20, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix_test = np.array(X_mix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_mix_test.shape\n",
    "d2_test_mix_dataset = X_mix_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "pred=clf.predict(d2_test_mix_dataset)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clfOCSV.predict(d2_test_mix_dataset)\n",
    "unique_elements, counts_elements = np.unique(pred, return_counts=True)\n",
    "print(\"\\t\",unique_elements,\"    \",counts_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcionalidad extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add noise only to Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "X = np.concatenate([target_data+noise, nontarget_data])\n",
    "Y = np.concatenate([np.ones(target_data.shape[0]), np.zeros(nontarget_data.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "nsamples, nx, ny = X.shape\n",
    "d2_train_dataset = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(),RandomForestClassifier(max_depth=2, random_state=0))\n",
    "\n",
    "preds = np.empty(len(Y))\n",
    "for train, test in cv.split(d2_train_dataset, Y):\n",
    "    clf.fit(d2_train_dataset[train], Y[train])\n",
    "    preds[test] = clf.predict(d2_train_dataset[test])\n",
    "\n",
    "# Info del proceso\n",
    "target_names = ['NonNoise', 'Noise']\n",
    "report = classification_report(Y, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_noise = 1\n",
    "noise = np.random.normal(0.0, max_noise, nontarget_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add noise only to NonTarget data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "X = np.concatenate([target_data, nontarget_data+noise])\n",
    "Y = np.concatenate([np.ones(target_data.shape[0]), np.zeros(nontarget_data.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "nsamples, nx, ny = X.shape\n",
    "d2_train_dataset = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(),RandomForestClassifier(max_depth=2, random_state=0))\n",
    "\n",
    "preds = np.empty(len(Y))\n",
    "for train, test in cv.split(d2_train_dataset, Y):\n",
    "    clf.fit(d2_train_dataset[train], Y[train])\n",
    "    preds[test] = clf.predict(d2_train_dataset[test])\n",
    "\n",
    "target_names = ['NonNoise', 'Noise']\n",
    "report = classification_report(Y, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "X = np.concatenate([target_data, nontarget_data])\n",
    "Y = np.concatenate([np.zeros(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
